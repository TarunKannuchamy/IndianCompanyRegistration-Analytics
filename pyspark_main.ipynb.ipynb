{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/spark2.4.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = ss.read.csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "# import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating table products\n",
    "# File location and type\n",
    "file_location = \"/user/kolpurath6035/registered_companies.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = ss.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_of_registration: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df = df.withColumn(\"date_of_registration\",F.date_format(F.to_date(\"date_of_registration\", \"dd-MM-yyyy\"), \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"latest_year_annual_return\",F.date_format(F.to_date(\"latest_year_annual_return\", \"dd-MM-yyyy\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df.select(\"date_of_registration\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"PAIDUP_CAPITAL\",df.PAIDUP_CAPITAL.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|       company_class|  count|\n",
      "+--------------------+-------+\n",
      "|              Public| 137612|\n",
      "|                null|   5078|\n",
      "|             Private|1819264|\n",
      "|Private(One Perso...|  30216|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Based on the class display the number of companies\n",
    "df1 = df.select(\"corporate_identification_number\",\"company_class\")\n",
    "df1 = df1.groupBy(\"company_class\").count()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n",
      "|      decade|no_of_companies|\n",
      "+------------+---------------+\n",
      "|        null|           2525|\n",
      "| 1850 - 1859|              1|\n",
      "| 1860 - 1869|              3|\n",
      "| 1870 - 1879|             24|\n",
      "| 1880 - 1889|             36|\n",
      "| 1890 - 1899|             57|\n",
      "| 1900 - 1909|            887|\n",
      "| 1910 - 1919|            934|\n",
      "| 1920 - 1929|           1827|\n",
      "| 1930 - 1939|           3378|\n",
      "| 1940 - 1949|          10808|\n",
      "| 1950 - 1959|           9475|\n",
      "| 1960 - 1969|          11818|\n",
      "| 1970 - 1979|          30666|\n",
      "| 1980 - 1989|         143785|\n",
      "| 1990 - 1999|         344661|\n",
      "| 2000 - 2009|         439820|\n",
      "| 2010 - 2019|         978716|\n",
      "| 2020 - 2029|          12747|\n",
      "|invalid_year|              2|\n",
      "+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. list the number of companies that had been registered in each decade\n",
    "@udf(returnType=StringType())\n",
    "def find_decade(year):\n",
    "    if year is None:\n",
    "        return None\n",
    "    else:\n",
    "        dec1 = (year - (year % 10))\n",
    "        dec2 = dec1+9\n",
    "        dec = (f\"{dec1} - {dec2}\")\n",
    "        if(dec1<1000 or dec1>2023):\n",
    "            return \"invalid_year\"\n",
    "        else:\n",
    "            return dec\n",
    "df2 = df.select(\"corporate_identification_number\",\"company_name\",year(\"date_of_registration\").alias(\"year\"))\n",
    "df2 = df2.withColumn(\"decade\", find_decade(col(\"year\")))\n",
    "decade_df = df2\n",
    "df2 = df2.groupBy(\"decade\").agg(count(\"*\").alias(\"no_of_companies\")).orderBy(col(\"decade\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------------------+----+--------------+-----+----+\n",
      "|corporate_identification_number|        company_name|year|paidup_capital|check|rank|\n",
      "+-------------------------------+--------------------+----+--------------+-----+----+\n",
      "|           U74140MH2000PLC12...|RELOGISTICS INFRA...|2000|    2101913000|  yes|   1|\n",
      "|           U85110KA2000PLC02...|NANDI ECONOMIC CO...|2000|    2090466920|  yes|   2|\n",
      "|           L72200MH2000PLC13...|MW UNITEXX LIMITE...|2000|    2087292760|  yes|   3|\n",
      "|           L85110KA2000PLC02...|NARAYANA HRUDAYAL...|2000|    2043608040|  yes|   4|\n",
      "|           U45200DL2000PLC15...|PIPAVAV RAILWAY C...|2000|    1960000200|  yes|   5|\n",
      "|           U74210PN2004PTC14...|EON HADAPSAR INFR...|2004|    2131500000|  yes|   1|\n",
      "|           U74140KA2004PTC03...|SANYO BPL PRIVATE...|2004|    2089333780|  yes|   2|\n",
      "|           U45200TG2004PLC04...|GKC PROJECTS LIMI...|2004|    2050787020|  yes|   3|\n",
      "|           U28910MH2004PLC20...|FIRST FORGE LIMIT...|2004|    2033333330|  yes|   4|\n",
      "|           U51909MH2004PLC14...|FIRESTAR INTERNAT...|2004|    1946501420|  yes|   5|\n",
      "|           U29221KA2008PTC04...|BOSCH AUTOMOTIVE ...|2008|    2130769230|  yes|   1|\n",
      "|           L55101KA2008PLC04...|COFFEE DAY ENTERP...|2008|    2112517190|  yes|   2|\n",
      "|           U34102TN2008PLC06...|ASHLEY POWERTRAIN...|2008|    2091004190|  yes|   3|\n",
      "|           U72900KL2008SGC02...|KERALA STATE INFO...|2008|    2049592000|  yes|   4|\n",
      "|           U45203MH2008PLC18...|RAJAHMUNDRY GODAV...|2008|    2039589000|  yes|   5|\n",
      "|           U74900HR2012PTC04...|NACHI TECHNOLOGY ...|2012|    2100000000|  yes|   1|\n",
      "|           U40300TN2012PTC08...|HEXA INDUSTRIES P...|2012|    2091810000|  yes|   2|\n",
      "|           U40108TG2012PTC08...|MYTRAH VAYU (MANJ...|2012|    2084506870|  yes|   3|\n",
      "|           U15122MH2012PLC23...|SAHARA PURE EATAB...|2012|    2050500000|  yes|   4|\n",
      "|           U17120KA2012FTC06...|SEIREN INDIA PRIV...|2012|    2050000000|  yes|   5|\n",
      "|           U45200MH2016PLC28...|CG TOLLWAY LIMITE...|2016|    2035000000|  yes|   1|\n",
      "|           U29292PN2016PTC15...|ILJIN GLOBAL INDI...|2016|    2018850000|  yes|   2|\n",
      "|           U74999GJ2016PLC09...|SURAT SMART CITY ...|2016|    2000000000|  yes|   3|\n",
      "|           U75100MP2016SGC03...|INDORE SMART CITY...|2016|    2000000000|  yes|   3|\n",
      "|           U70102AP2016PLC09...|KAKINADA SMART CI...|2016|    2000000000|  yes|   3|\n",
      "|           U24200MH2016PTC27...|JSW PAINTS PRIVAT...|2016|    2000000000|  yes|   3|\n",
      "|           U74140GJ2016PLC08...|SMART CITY AHMEDA...|2016|    2000000000|  yes|   3|\n",
      "|           U70100MP2016SGC03...|BHOPAL SMART CITY...|2016|    2000000000|  yes|   3|\n",
      "|           U65990MH2016PTC27...|INDOSTAR HOME FIN...|2016|    2000000000|  yes|   3|\n",
      "|           U75100MP2016SGC03...|JABALPUR SMART CI...|2016|    2000000000|  yes|   3|\n",
      "|           U75100MP2016SGC04...|GWALIOR SMART CIT...|2016|    2000000000|  yes|   3|\n",
      "|           U75140KL2016SGC04...|COCHIN SMART MISS...|2016|    2000000000|  yes|   3|\n",
      "|           U74999KA2016PLC09...|BELAGAVI SMART CI...|2016|    2000000000|  yes|   3|\n",
      "|           U74900AP2016PLC09...|GREATER VISAKHAPA...|2016|    2000000000|  yes|   3|\n",
      "|           U74999MH2016SGC28...|NAGPUR SMART AND ...|2016|    2000000000|  yes|   3|\n",
      "|           U75100MP2016SGC04...|UJJAIN SMART CITY...|2016|    2000000000|  yes|   3|\n",
      "|           U75144RJ2016SGC04...|JAIPUR SMART CITY...|2016|    2000000000|  yes|   3|\n",
      "|           U75144RJ2016SGC04...|UDAIPUR SMART CIT...|2016|    2000000000|  yes|   3|\n",
      "|           U75232RJ2016SGC05...|KOTA SMART CITY L...|2016|    2000000000|  yes|   3|\n",
      "|           U74999KA2016PLC09...|DAVANAGERE SMART ...|2016|    2000000000|  yes|   3|\n",
      "|           U65922MH2016PLC27...|CENTRUM HOUSING F...|2016|    1982177860|  yes|   4|\n",
      "|           U93000PN2016SGC15...|PUNE SMART CITY D...|2016|    1960000000|  yes|   5|\n",
      "|           U31900HR2020FTC08...|ATLBATTERY TECHNO...|2020|    1793500000|  yes|   1|\n",
      "|           U45201UR2020PTC01...|BHARAT CONSTRUCTI...|2020|     762674880|  yes|   2|\n",
      "|           U51909PN2020FTC18...|HENGLI HYDRAULIC ...|2020|     560000000|  yes|   3|\n",
      "|           U17299HR2020FTC08...|XIYIN INDIA PRIVA...|2020|     360000000|  yes|   4|\n",
      "|           U72900MH2020FTC33...|MUFG ENTERPRISE S...|2020|     312000000|  yes|   5|\n",
      "+-------------------------------+--------------------+----+--------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. find top 5 companies with highest paid up capital as a list in each leap year after 2000\n",
    "@udf(returnType=StringType())\n",
    "def check_year(year):\n",
    "    if year is None:\n",
    "        return None\n",
    "    else:\n",
    "        if(year<1000 or year>2023):\n",
    "                return \"invalid_year\"\n",
    "        elif (year>=2000):\n",
    "            if (year%4==0):\n",
    "                return \"yes\"\n",
    "            else:\n",
    "                return \"no\"\n",
    "        else:\n",
    "            return \"no\"\n",
    "df3 = df.select(\"corporate_identification_number\",\"company_name\",year(\"date_of_registration\").alias(\"year\"),\"paidup_capital\")\n",
    "df3 = df3.withColumn(\"check\",check_year(\"year\"))\n",
    "df3 = df3.filter(col(\"check\")==\"yes\").orderBy(\"corporate_identification_number\",\"company_name\",\"year\")\n",
    "df3 = df3.withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"year\").orderBy(col(\"paidup_capital\").desc())))\n",
    "df3 = df3.filter(col(\"rank\")<=5).orderBy(\"year\",\"rank\")\n",
    "df3.show(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-11f69a1598fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"append\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/user/kolpurath6035/new_query\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/spark2.4.3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjavaToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_rdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/spark2.4.3/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df3.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------------------+--------------------+--------------+----+\n",
      "|corporate_identification_number|        company_name|    registered_state|paidup_capital|rank|\n",
      "+-------------------------------+--------------------+--------------------+--------------+----+\n",
      "|           U74999AN1988SGC00...|ANDAMAN AND NICOB...|Andaman and Nicob...|     109700600|   1|\n",
      "|           U15209AP2006PTC04...|SRI VIJAYA VISAKH...|      Andhra Pradesh|    2129403500|   1|\n",
      "|           U40101AR2013PLC00...|ARUNACHAL HYDRO P...|   Arunachal Pradesh|    1643000000|   1|\n",
      "|           L23209AS1974GOI00...|BONGAIGAON REFINE...|               Assam|    1998179000|   1|\n",
      "|           U40100BR1982SGC00...|BIHAR STATE HYDRO...|               Bihar|     990400000|   1|\n",
      "|           U63010CH2013GOI03...|PUNJAB LOGISTICS ...|          Chandigarh|    1985150000|   1|\n",
      "|           U13100CT2008GOI02...|NMDC-CMDC LIMITED   |         Chattisgarh|    1928377180|   1|\n",
      "|           L74999DN1987PLC00...|K-LIFESTYLE & IND...|Dadra and Nagra H...|    1017804000|   1|\n",
      "|           L67120DD1987PLC00...|      PSL LIMITED   |       Daman and Diu|    1249344840|   1|\n",
      "|           U40105DL2018PTC33...|SBESS SERVICES PR...|               Delhi|    2145926750|   1|\n",
      "|           U55101GA2009PTC00...|VMSALGAOCAR HOTEL...|                 Goa|    1802100000|   1|\n",
      "|           U15400GJ2019PLC10...|ZYDUS WELLNESS PR...|             Gujarat|    2144272980|   1|\n",
      "|           U15500HR2010PLC04...|NOURISHCO BEVERAG...|             Haryana|    2130000000|   1|\n",
      "|           L24231HP1984PLC00...|MOREPEN LABORATOR...|    Himachal Pradesh|    2096172506|   1|\n",
      "|           U65920JK2005GOI00...|JAMMU AND KASHMIR...|   Jammu and Kashmir|     800000000|   1|\n",
      "|           U34101JH1993PTC00...|TATA CUMMINS PRIV...|           Jharkhand|    1800000000|   1|\n",
      "|           U29221KA2008PTC04...|BOSCH AUTOMOTIVE ...|           Karnataka|    2130769230|   1|\n",
      "|           U55209KL2010PTC02...|TABLEZ FOOD COMPA...|              Kerala|    2115285950|   1|\n",
      "|           U05004LD1987GOI00...|LAKSHADWEEP DEVEL...|         Lakshadweep|      65041000|   1|\n",
      "|           U75100MP2016SGC04...|GWALIOR SMART CIT...|      Madhya Pradesh|    2000000000|   1|\n",
      "|           U75100MP2016SGC04...|UJJAIN SMART CITY...|      Madhya Pradesh|    2000000000|   1|\n",
      "|           U70100MP2016SGC03...|BHOPAL SMART CITY...|      Madhya Pradesh|    2000000000|   1|\n",
      "|           U75100MP2016SGC03...|JABALPUR SMART CI...|      Madhya Pradesh|    2000000000|   1|\n",
      "|           U75100MP2016SGC03...|INDORE SMART CITY...|      Madhya Pradesh|    2000000000|   1|\n",
      "|           U45201PN1987PTC04...|AVINASH BHOSALE I...|         Maharashtra|    2146500000|   1|\n",
      "|           U40101MN2009GOI00...|LOKTAK DOWNSTREAM...|             Manipur|    1233923090|   1|\n",
      "|           U26942ML1955SGC00...|MAWMLUH-CHERRA CE...|           Meghalaya|    1628285140|   1|\n",
      "|           U15134MZ1989SGC00...|MIZORAM FOOD AND ...|             Mizoram|     197830900|   1|\n",
      "|           U21012NL1971SGC00...|NAGALAND PULP & P...|            Nagaland|    1177500700|   1|\n",
      "|           U27109OR1999SGC00...|IDCOL KALINGA IRO...|              Orissa|    1501000000|   1|\n",
      "|           U93000PY2017PTC00...|SPI TECHNOLOGIES ...|         Pondicherry|    1650746400|   1|\n",
      "|           L24231PB1961PLC00...|RANBAXY LABORATOR...|              Punjab|    2128317485|   1|\n",
      "|           U13100RJ1969SGC00...|RAJASTHAN STATE I...|           Rajasthan|    2101858000|   1|\n",
      "|           U74999SK2016PTC01...|PANDIM ONLINE SOL...|              Sikkim|        100000|   1|\n",
      "|           U63030SK2016PTC01...|TRIP OF LIFETIME ...|              Sikkim|        100000|   1|\n",
      "|           U65929TN2010PLC07...|SHRIRAM HOUSING F...|          Tamil Nadu|    2141600000|   1|\n",
      "|           U45200TG2005PTC09...|JADCHERLA EXPRESS...|           Telangana|    2100402530|   1|\n",
      "|           U17119TR1974SGC00...|TRIPURA JUTE MILL...|             Tripura|    1110401000|   1|\n",
      "|           L34101UP1972PLC00...|      LML LIMITED   |       Uttar Pradesh|    2004095100|   1|\n",
      "|           U55101UR2009PTC03...|MAHANANDA SPA AND...|         Uttaranchal|    1354921350|   1|\n",
      "|           U51909WB1995PLC07...|CONCAST STEEL & P...|         West Bengal|    2132178800|   1|\n",
      "+-------------------------------+--------------------+--------------------+--------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. find top 5 companies that has highest paid up capital in each state\n",
    "df4 = df.select(\"corporate_identification_number\",\"company_name\",\"registered_state\",\"paidup_capital\")\n",
    "df4 = df4.withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"registered_state\").orderBy(col(\"paidup_capital\").desc())))\n",
    "df4 = df4.filter(col(\"rank\")<=1).orderBy(\"registered_state\",\"rank\")\n",
    "df4.show(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. which state has highest companies registered\n",
    "df5 = df.select(\"corporate_identification_number\",\"company_name\",\"registered_state\")\n",
    "df5 = df5.groupBy(\"registered_state\").agg(count(\"*\").alias(\"num_of_companies\")).orderBy(col(\"num_of_companies\").desc())\n",
    "df5.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. find the year on which each state has their maximum registration\n",
    "df6 = df.select(\"corporate_identification_number\",\"company_name\",\"registered_state\",year(\"date_of_registration\").alias(\"year\"))\n",
    "df6 = df6.groupBy(\"registered_state\",\"year\").agg(count(\"*\").alias(\"no_of_companies\"))\n",
    "df6 = df6.withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"registered_state\").orderBy(col(\"no_of_companies\").desc())))\n",
    "df6 = df6.filter(col(\"rank\")==1).orderBy(col(\"registered_state\"))\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+----+\n",
      "|    registered_state|       company_class|no_of_companies|rank|\n",
      "+--------------------+--------------------+---------------+----+\n",
      "|            Nagaland|             Private|            560|   1|\n",
      "|            Nagaland|              Public|             49|   2|\n",
      "|            Nagaland|Private(One Perso...|             11|   3|\n",
      "|           Karnataka|             Private|         117309|   1|\n",
      "|           Karnataka|              Public|           4811|   2|\n",
      "|           Karnataka|Private(One Perso...|           3191|   3|\n",
      "|           Karnataka|                null|            468|   4|\n",
      "|Dadra and Nagra H...|             Private|            442|   1|\n",
      "|Dadra and Nagra H...|              Public|            104|   2|\n",
      "|Dadra and Nagra H...|Private(One Perso...|              4|   3|\n",
      "|              Kerala|             Private|          51449|   1|\n",
      "|              Kerala|              Public|           3876|   2|\n",
      "|              Kerala|Private(One Perso...|            698|   3|\n",
      "|              Kerala|                null|             75|   4|\n",
      "|          Tamil Nadu|             Private|         137173|   1|\n",
      "|          Tamil Nadu|              Public|          11237|   2|\n",
      "|          Tamil Nadu|Private(One Perso...|           2127|   3|\n",
      "|          Tamil Nadu|                null|            334|   4|\n",
      "|      Andhra Pradesh|             Private|          30538|   1|\n",
      "|      Andhra Pradesh|              Public|           1610|   2|\n",
      "+--------------------+--------------------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. find the sector that is most common in each state\n",
    "df7 = df.select(\"corporate_identification_number\",\"company_name\",\"registered_state\",\"company_class\")\n",
    "df7 = df7.groupBy(\"registered_state\",\"company_class\").agg(count(\"*\").alias(\"no_of_companies\"))\n",
    "df7 = df7.withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"registered_state\").orderBy(col(\"no_of_companies\").desc())))\n",
    "df7 = df7.filter(col(\"rank\")==1).orderBy(col(\"registered_state\"))\n",
    "df7.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"overwrite\").csv(<path>)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 8. Based on sub_category give the count for companies in each state\n",
    "df8 = df.select(\"corporate_identification_number\",\"company_name\",\"registered_state\",\"company_sub_category\")\n",
    "df8 = df8.groupBy(\"registered_state\",\"company_sub_category\")\\\n",
    ".agg(count(\"*\").alias(\"no_of_companies\")).orderBy(\"registered_state\",\"company_sub_category\")\n",
    "df8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------------------+--------------------+----------+----+\n",
      "|corporate_identification_number|        company_name|    registered_state|      date|rank|\n",
      "+-------------------------------+--------------------+--------------------+----------+----+\n",
      "|           U51909AN2020PTC00...|ANDAMAN RUPSHA MA...|Andaman and Nicob...|2020-01-13|   1|\n",
      "|           U92410AN2020PTC00...|LILIUM ADVENTURE ...|Andaman and Nicob...|2020-01-03|   2|\n",
      "|           U74999AN2019PTC00...|TAURINE FILMS AND...|Andaman and Nicob...|2019-12-20|   3|\n",
      "|           U70109AN2019PTC00...|KMS DREAM CREATIO...|Andaman and Nicob...|2019-12-16|   4|\n",
      "|           U60221AN2019PTC00...|DE WHALEN PARADIS...|Andaman and Nicob...|2019-12-06|   5|\n",
      "|           U63031AN2019PTC00...|INFO INDIA TOUR A...|Andaman and Nicob...|2019-11-21|   6|\n",
      "|           U63031AN2019PTC00...|PARWATI MULTI-SEC...|Andaman and Nicob...|2019-11-14|   7|\n",
      "|           U26990AN2019PTC00...|MITTAL ROOFING PR...|Andaman and Nicob...|2019-10-24|   8|\n",
      "|           U63030AN2019PTC00...|NICO TECHNOLOGIES...|Andaman and Nicob...|2019-10-18|   9|\n",
      "|           U61100AN2019PTC00...|DWEEP ENGINEERING...|Andaman and Nicob...|2019-10-09|  10|\n",
      "|           U05002AN2019PTC00...|NOORY FISHERIES P...|Andaman and Nicob...|2019-10-09|  10|\n",
      "|           U72900AN2019PTC00...|NOUVEAU TECHSOLUT...|Andaman and Nicob...|2019-09-24|  11|\n",
      "|           U22300AN2019PTC00...|HIFI7 FIBERNET PR...|Andaman and Nicob...|2019-09-19|  12|\n",
      "|           U85300AN2019NPL00...|GV KACHREWAALE FO...|Andaman and Nicob...|2019-09-18|  13|\n",
      "|           U45309AN2019PTC00...|S.C.B PROJECTS PR...|Andaman and Nicob...|2019-09-16|  14|\n",
      "|           U29309AN2019PTC00...|BLUEMINE MARINE S...|Andaman and Nicob...|2019-09-09|  15|\n",
      "|           U51909AP2020PTC11...|SUBA PRADA OILS P...|      Andhra Pradesh|2020-01-31|   1|\n",
      "|           U15549AP2020PTC11...|GURUBILLI FOOD PR...|      Andhra Pradesh|2020-01-31|   1|\n",
      "|           U74999AP2020OPC11...|AAA SGP MEDIA (OP...|      Andhra Pradesh|2020-01-31|   1|\n",
      "|           U24110AP2020PTC11...|KOTTAPALLI SURFAC...|      Andhra Pradesh|2020-01-31|   1|\n",
      "+-------------------------------+--------------------+--------------------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. list the companies that have been recently enrolled in each state\n",
    "df9 = df.select(\"corporate_identification_number\",\"company_name\",\"registered_state\",col(\"date_of_registration\").alias(\"date\"))\n",
    "df9 = df9.withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"registered_state\").orderBy(col(\"date\").desc())))\n",
    "df9 = df9.filter(col(\"rank\")<=15).orderBy(\"registered_state\",\"rank\")\n",
    "df9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. find the count of companies per company_status\n",
    "df10 = df.select(\"corporate_identification_number\",\"company_name\",\"company_status\")\n",
    "df10 = df10.groupBy(\"company_status\").agg(count(\"*\").alias(\"no_of_companies\")).orderBy(\"company_status\")\n",
    "df10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. find the top 2 companies per principal business activity in 19th century\n",
    "df11 = df.select(\"corporate_identification_number\",\"company_name\",\"paidup_capital\",year(\"date_of_registration\").alias(\"year\"),\"PRINCIPAL_BUSINESS_ACTIVITY_AS_PER_CIN\")\n",
    "df11 = df11.filter((col(\"year\")>1800) & (col(\"year\")<1900))\n",
    "df11 = df11.withColumn(\"rank\",dense_rank().over(Window.partitionBy(\"PRINCIPAL_BUSINESS_ACTIVITY_AS_PER_CIN\").orderBy(col(\"paidup_capital\").desc())))\n",
    "df11 = df11.filter(col(\"rank\")<=2).orderBy(\"PRINCIPAL_BUSINESS_ACTIVITY_AS_PER_CIN\",\"rank\")\n",
    "df11.show(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. find the company with higest paidup capital in each decade\n",
    "df12 = decade_df.select(\"corporate_identification_number\", \"decade\")\\\n",
    ".join(df.select(\"corporate_identification_number\",\"company_name\",\"paidup_capital\"),[\"corporate_identification_number\"],\"inner\")\n",
    "df12_2 = df12.groupBy(\"decade\").agg(max(col(\"paidup_capital\")).alias(\"paidup_capital\"))\n",
    "df12 = df12.select(\"corporate_identification_number\", \"company_name\", \"paidup_capital\", \"decade\") \\\n",
    "    .join(df12_2.select(\"*\"), [\"paidup_capital\", \"decade\"], \"inner\").orderBy(\"decade\")\n",
    "df12.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.rdd.coalesce(1).toDF().write.option(\"header\",True).mode(\"append\").csv(<path>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
